# CVAT - Anotacao Automatica com YOLOv3, DEXTR, SAM 1 e SAM 2 via Docker + Nuclio

Este repositÃ³rio/documentaÃ§Ã£o mostra como subir localmente o **CVAT** com suporte a **anotaÃ§Ã£o automÃ¡tica e assistida**, utilizando modelos baseados em deep learning como **YOLOv3**, **DEXTR**, **SAM 1** e **SAM 2**, via **Nuclio**.

---

## ğŸš€ PrÃ©-requisitos

- Docker + Docker Compose instalados
- Sistema operacional compatÃ­vel (Ubuntu 20.04+, WSL2 ou Mac)
- GPU + NVIDIA Container Toolkit (para SAM 1 e SAM 2)

---

## ğŸ“¦ Clonando o repositÃ³rio

```bash
git clone https://github.com/opencv/cvat
cd cvat
```

---

## âš™ï¸ Subindo o CVAT com suporte a modelos serverless

Use o `docker-compose.serverless.yml` para ativar os modelos automÃ¡ticos (YOLO, DEXTR, SAM, etc):

```bash
docker compose -f docker-compose.yml -f components/serverless/docker-compose.serverless.yml up -d --build
```

> âš ï¸ Aguarde o download e inicializaÃ§Ã£o de todos os containers (leva alguns minutos na primeira vez).

---

## ğŸŒ Expondo o CVAT para a rede local (WAN)

Por padrÃ£o, o CVAT escuta apenas no `localhost`. Para permitir acesso de outros dispositivos da rede (como `http://192.168.1.15:8080`):

1. No `docker-compose.yml`, altere os blocos de labels:

### `cvat_server`:
```yaml
labels:
  traefik.enable: "true"
  traefik.http.services.cvat.loadbalancer.server.port: "8080"
  traefik.http.routers.cvat.rule: PathPrefix(`/api/`) || PathPrefix(`/static/`) || PathPrefix(`/admin`) || PathPrefix(`/django-rq`)
  traefik.http.routers.cvat.entrypoints: web
```

### `cvat_ui`:
```yaml
labels:
  traefik.enable: "true"
  traefik.http.services.cvat-ui.loadbalancer.server.port: "80"
  traefik.http.routers.cvat-ui.rule: PathPrefix(`/`)
  traefik.http.routers.cvat-ui.entrypoints: web
```

2. Certifique-se que o serviÃ§o `traefik` estÃ¡ expondo as portas:
```yaml
ports:
  - 8080:8080
```

3. Reinicie os serviÃ§os:
```bash
docker compose down -v
docker compose -f docker-compose.yml -f components/serverless/docker-compose.serverless.yml up -d --build
```

Agora, acesse via IP da mÃ¡quina:
```
http://192.168.1.15:8080
```

---

## ğŸ”‘ Criando usuÃ¡rio administrador

```bash
docker exec -it cvat_server bash -ic 'python3 manage.py createsuperuser'
```

---

## ğŸ” Acessando o CVAT

```
http://192.168.1.15:8080
```

---

## ğŸ“¥ InstalaÃ§Ã£o do Nuclio CLI (`nuctl`)

```bash
# Baixar a versÃ£o mais recente do nuctl
curl -Lo nuctl https://github.com/nuclio/nuclio/releases/download/1.13.23/nuctl-1.13.23-linux-amd64

# Tornar executÃ¡vel
chmod +x nuctl

# Mover para um diretÃ³rio do PATH
sudo mv nuctl /usr/local/bin/

# Verificar a instalaÃ§Ã£o
nuctl version
```

> ğŸ’¡ O comando `nuctl` precisa estar disponÃ­vel no terminal antes de executar os scripts de deploy.

---

## ğŸ’» InstalaÃ§Ã£o de drivers NVIDIA + CUDA Toolkit (para SAM 1 e SAM 2)

```bash
# Instalar suporte a drivers automÃ¡ticos e listar opÃ§Ãµes
apt install ubuntu-drivers-common -y
ubuntu-drivers devices

# Instalar driver recomendado (ex: 550)
sudo apt install nvidia-driver-550 -y

# Instalar toolkit para containers NVIDIA
distribution=$(. /etc/os-release; echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list \
  | sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#' \
  | sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list > /dev/null
sudo apt update
sudo apt install -y nvidia-container-toolkit
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker

# (Opcional) Instalar GCC se nÃ£o tiver
sudo apt-get install gcc -y

# Instalar CUDA Toolkit 12.8
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt-get update
sudo apt-get -y install cuda-toolkit-12-8

# Configurar variÃ¡veis de ambiente
export PATH=/usr/local/cuda/bin${PATH:+:$PATH}
export LD_LIBRARY_PATH=/usr/local/cuda-12.2/lib64${LD_LIBRARY_PATH:+:$LD_LIBRARY_PATH}

# Testar
nvcc -V
```

---

## ğŸ¤– Deploy dos modelos YOLOv3 e DEXTR (CPU)

```bash
./serverless/deploy_cpu.sh serverless/openvino/dextr
./serverless/deploy_cpu.sh serverless/openvino/omz/public/yolo-v3-tf
```

> Isso registrarÃ¡ os modelos no painel Nuclio (`http://localhost:8070`) e permitirÃ¡ seu uso no CVAT.

---

## ğŸ§  Deploy do SAM 1 (GPU)

```bash
./serverless/deploy_gpu.sh serverless/pytorch/facebookresearch/sam
```

> Reinicie os containers CVAT apÃ³s o deploy:
```bash
docker compose restart
```

---

## ğŸ§ª Deploy do SAM 2 (custom, GPU)

1. Clone ou copie os arquivos `function-gpu.yaml`, `main.py`, `model_handler.py` e `requirements.txt` para uma pasta:

```
sam2/
  â””â”€â”€ nuclio/
      â”œâ”€â”€ function-gpu.yaml
      â”œâ”€â”€ main.py
      â”œâ”€â”€ model_handler.py
      â””â”€â”€ requirements.txt
```

2. Execute:
```bash
./deploy_gpu.sh sam2/nuclio
```

3. Reinicie o CVAT:
```bash
docker compose restart
```

> O modelo `nuclio-sam2` aparecerÃ¡ no menu **Actions > Automatic Annotation**.

---

## ğŸ§‘â€ğŸ’» Usando a anotaÃ§Ã£o automÃ¡tica na interface

1. No CVAT, crie uma `Task`
2. FaÃ§a upload de imagens (ex: `lenna.png`)
3. Crie um label (ex: `person`)
4. Acesse o Job da imagem
5. Clique em `Actions â†’ Automatic Annotation`
6. Escolha o modelo (YOLOv3, DEXTR, SAM 1, SAM 2)
7. Mapeie os labels e clique em **Annotate**
8. Clique em **Save**

---

## ğŸ“„ Exportando anotaÃ§Ãµes

- `Actions â†’ Export annotations`
- Formatos suportados: COCO, YOLO, Pascal VOC, XML, etc.

---

## ğŸ“Š Comparativo de Modelos

| Modelo  | Tipo       | Suporte     | Framework       | Recurso | Labels | Tipos de tarefa |
|---------|------------|-------------|------------------|---------|--------|-----------------|
| YOLOv3  | DetecÃ§Ã£o   | Oficial     | OpenVINO         | CPU     | person, car... | Caixa delimitadora |
| DEXTR   | SegmentaÃ§Ã£o| Oficial     | OpenVINO         | CPU     | custom          | SegmentaÃ§Ã£o interativa |
| SAM 1   | SegmentaÃ§Ã£o| Oficial     | PyTorch + CUDA    | GPU     | custom          | SegmentaÃ§Ã£o assistida |
| SAM 2   | SegmentaÃ§Ã£o| Custom      | PyTorch 2.4 + CUDA 12.4 | GPU | custom          | SegmentaÃ§Ã£o assistida |

---

## ğŸ“š ReferÃªncias

- [CVAT Docs](https://docs.cvat.ai/)
- [Nuclio Docs](https://nuclio.io/docs/latest/)
- [Segment Anything v1](https://github.com/facebookresearch/segment-anything)
- [Segment Anything v2](https://github.com/facebookresearch/segment-anything-2)

---

## ğŸ§ª Como foi feita a personalizaÃ§Ã£o do SAM 2 no CVAT

### ğŸ“ Estrutura mÃ­nima de uma funÃ§Ã£o customizada no Nuclio para CVAT

VocÃª seguiu (corretamente) a estrutura baseada no SAM 1:

```
sam2/
  â””â”€â”€ nuclio/
      â”œâ”€â”€ function-gpu.yaml     # Define a imagem base, variÃ¡veis de ambiente, handler e limites
      â”œâ”€â”€ main.py               # Handler da funÃ§Ã£o (interface HTTP do Nuclio)
      â”œâ”€â”€ model_handler.py      # LÃ³gica da inferÃªncia real do modelo
      â””â”€â”€ requirements.txt      # DependÃªncias
```

---

### ğŸ”§ `function-gpu.yaml` - ConfiguraÃ§Ã£o da funÃ§Ã£o

VocÃª definiu:

- **`baseImage`** com suporte Ã  GPU e compatÃ­vel com PyTorch 2.4 e CUDA 12.4
- **`directives`** para instalar dependÃªncias como `segment-anything-2` e libs auxiliares
- **`handler`** apontando para `main:handler`
- **`resources.limits.nvidia.com/gpu: 1`** garantindo que a funÃ§Ã£o vai rodar com GPU
- **`env`** customizados para carregar diferentes modelos/configs do SAM 2

Isso permite **trocar o modelo usado sem alterar cÃ³digo**:

```yaml
- kind: ENV
  value: MODEL="sam2_hiera_large.pt"
- kind: ENV
  value: MODEL_CFG="sam2_hiera_l.yaml"
```

---

### ğŸ§  `main.py` e `model_handler.py`

- O `main.py` expÃµe um `handler` HTTP que:
  - Recebe `image` + `points` + `labels`
  - Chama o `ModelHandler` com esses dados

- O `model_handler.py` Ã© responsÃ¡vel por:
  - Carregar o modelo SAM 2 (com o checkpoint e config passados via ENV)
  - Aplicar a inferÃªncia com base nos pontos recebidos
  - Retornar a mÃ¡scara em formato que o CVAT entende (array binÃ¡rio â†’ PNG ou RLE â†’ base64)

---

## âœ… Como o CVAT reconhece a funÃ§Ã£o no painel

Assim que vocÃª executa:

```bash
./deploy_gpu.sh sam2/nuclio
```

A funÃ§Ã£o `nuclio-sam2` (ou qualquer nome que vocÃª definir na `function-gpu.yaml`) Ã© registrada no Nuclio e automaticamente lida pelo CVAT **via API interna**.

O CVAT entÃ£o **lista essa funÃ§Ã£o** como um modelo disponÃ­vel em:

```
Actions â†’ Automatic Annotation
```

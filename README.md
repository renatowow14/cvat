# CVAT - Anota√ß√£o Autom√°tica com YOLOv3, DEXTR, SAM 1 e SAM 2 via Docker + Nuclio

Este reposit√≥rio/documenta√ß√£o demonstra como configurar localmente o **CVAT** com suporte √† **anota√ß√£o autom√°tica e assistida**, utilizando modelos baseados em deep learning como **YOLOv3**, **DEXTR**, **SAM 1** e **SAM 2**, integrados via **Nuclio**.

---

## üöÄ Pr√©-requisitos

- Docker + Docker Compose instalados
- Sistema operacional compat√≠vel (Ubuntu 20.04+, WSL2 ou Mac)
- GPU + NVIDIA Container Toolkit (necess√°rio para SAM 1 e SAM 2)

---

## üì¶ Clonando o reposit√≥rio

```bash
git clone https://github.com/opencv/cvat
cd cvat
```

---

## ‚öôÔ∏è Subindo o CVAT com suporte a modelos serverless

Utilizar o `docker-compose.serverless.yml` para ativar os modelos autom√°ticos (YOLO, DEXTR, SAM, etc):

```bash
docker compose -f docker-compose.yml -f components/serverless/docker-compose.serverless.yml -f docker-compose.custom.override.yml up -d --build
```

> ‚ö†Ô∏è √â necess√°rio aguardar o download e inicializa√ß√£o de todos os containers (pode levar alguns minutos na primeira execu√ß√£o).

---

## üåê Expondo o CVAT para a rede local (WAN)

Por padr√£o, o CVAT escuta apenas no `localhost`. Para permitir o acesso a partir de outros dispositivos da rede (como `http://192.168.1.15:8080`):

1. No arquivo `docker-compose.yml`, ajustar os blocos de labels:

### `cvat_server`:
```yaml
labels:
  traefik.enable: "true"
  traefik.http.services.cvat.loadbalancer.server.port: "8080"
  traefik.http.routers.cvat.rule: PathPrefix(`/api/`) || PathPrefix(`/static/`) || PathPrefix(`/admin`) || PathPrefix(`/django-rq`)
  traefik.http.routers.cvat.entrypoints: web
```

### `cvat_ui`:
```yaml
labels:
  traefik.enable: "true"
  traefik.http.services.cvat-ui.loadbalancer.server.port: "80"
  traefik.http.routers.cvat-ui.rule: PathPrefix(`/`)
  traefik.http.routers.cvat-ui.entrypoints: web
```

2. Garantir que o servi√ßo `traefik` esteja expondo as portas corretamente:
```yaml
ports:
  - 8080:8080
```

3. Reiniciar os servi√ßos:
```bash
docker compose down -v
docker compose -f docker-compose.yml -f components/serverless/docker-compose.serverless.yml up -d --build
```

A partir disso, o acesso poder√° ser realizado via IP da m√°quina:
```
http://192.168.1.15:8080
```

---

## üìÇ Configura√ß√£o de volume compartilhado (`/mnt/share`)

***Refer√™ncia: [*Share Storage*](https://docs.cvat.ai/docs/administration/basics/installation/#share-path)***

Para facilitar a **importa√ß√£o/exporta√ß√£o de dados** e permitir acesso a arquivos em m√∫ltiplos workers, configuramos um volume compartilhado entre os servi√ßos do CVAT.

### üõ†Ô∏è Etapas de configura√ß√£o

1. Criar o diret√≥rio compartilhado no host:
```bash
mkdir -p /mnt/share
chmod 777 /mnt/share
```

2. Criar um arquivo `docker-compose.custom.override.yml` com o conte√∫do:

```yaml
services:
  cvat_server:
    volumes:
      - cvat_share:/home/django/share:ro

  cvat_worker_import:
    volumes:
      - cvat_share:/home/django/share:ro

  cvat_worker_export:
    volumes:
      - cvat_share:/home/django/share:ro

  cvat_worker_annotation:
    volumes:
      - cvat_share:/home/django/share:ro

  cvat_worker_chunks:
    volumes:
      - cvat_share:/home/django/share:ro

volumes:
  cvat_share:
    driver_opts:
      type: none
      device: /mnt/share
      o: bind
```

> üîí O uso de `:ro` (read-only) garante que os containers n√£o modifiquem os arquivos do host acidentalmente.

3. Subir o CVAT com o override ativado:

```bash
docker compose \
  -f docker-compose.yml \
  -f docker-compose.custom.override.yml \
  -f components/serverless/docker-compose.serverless.yml \
  up -d --build
```

4. Verificar se o volume est√° montado corretamente:

```bash
docker exec -it cvat_server ls /home/django/share
```

5. Teste funcional:

```bash
echo "üî• Teste de volume OK" > /mnt/share/teste.txt
docker exec -it cvat_server cat /home/django/share/teste.txt
```

> ‚úÖ Voc√™ dever√° ver a mensagem "üî• Teste de volume OK", provando que o CVAT est√° lendo corretamente o conte√∫do do volume compartilhado.

---

## üîë Criando usu√°rio administrador

```bash
docker exec -it cvat_server bash -ic 'python3 manage.py createsuperuser'
```

---

## üîé Acessando o CVAT

```
http://192.168.1.15:8080
```

---

## üì• Instala√ß√£o do Nuclio CLI (`nuctl`)

```bash
curl -Lo nuctl https://github.com/nuclio/nuclio/releases/download/1.13.23/nuctl-1.13.23-linux-amd64
chmod +x nuctl
sudo mv nuctl /usr/local/bin/
nuctl version
```

> üí° O comando `nuctl` precisa estar dispon√≠vel no terminal antes de executar os scripts de deploy.

---

## üíª Instala√ß√£o de drivers NVIDIA + CUDA Toolkit (para SAM 1 e SAM 2)

```bash
apt install ubuntu-drivers-common -y
ubuntu-drivers devices
sudo apt install nvidia-driver-550 -y

distribution=$(. /etc/os-release; echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list \
  | sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#' \
  | sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list > /dev/null
sudo apt update
sudo apt install -y nvidia-container-toolkit
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker

sudo apt-get install gcc -y

wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt-get update
sudo apt-get -y install cuda-toolkit-12-8

export PATH=/usr/local/cuda/bin${PATH:+:$PATH}
export LD_LIBRARY_PATH=/usr/local/cuda-12.2/lib64${LD_LIBRARY_PATH:+:$LD_LIBRARY_PATH}

nvcc -V
```

---

## ü§ñ Deploy dos modelos YOLOv3 e DEXTR (CPU)

```bash
./serverless/deploy_cpu.sh serverless/openvino/dextr
./serverless/deploy_cpu.sh serverless/openvino/omz/public/yolo-v3-tf
```

---

## üß† Deploy do SAM 1 (GPU)

```bash
./serverless/deploy_gpu.sh serverless/pytorch/facebookresearch/sam
docker compose restart
```

---

## üß™ Deploy do SAM 2 (custom, GPU)

1. Clonar ou copiar os arquivos `function-gpu.yaml`, `main.py`, `model_handler.py` para uma pasta, e o script `deploy_gpu.sh` para o diret√≥rio raiz:

```
deploy_gpu.sh                # Script que faz o deploy da fun√ß√£o via nuctl
sam2/
  ‚îî‚îÄ‚îÄ nuclio/
      ‚îú‚îÄ‚îÄ function-gpu.yaml  # Configura√ß√£o da fun√ß√£o Nuclio (GPU, ENV, modelo)
      ‚îú‚îÄ‚îÄ main.py            # Fun√ß√£o HTTP que trata a requisi√ß√£o do CVAT
      ‚îî‚îÄ‚îÄ  model_handler.py   # Classe que roda a infer√™ncia do SAM2
```

---

2. Executar o script:

```bash
./deploy_gpu.sh sam2/nuclio
docker compose restart
```

> ‚úÖ O modelo `nuclio-sam2` aparecer√° no menu **Actions > Automatic Annotation** do CVAT automaticamente ap√≥s o deploy.

---

Se quiser, posso tamb√©m te devolver todo o `README.md` atualizado j√° com esse trecho inclu√≠do no lugar. Deseja?
2. Executar:
```bash
./deploy_gpu.sh sam2/nuclio
docker compose restart
```

> O modelo `nuclio-sam2` aparecer√° no menu **Actions > Automatic Annotation**.

---

## üìà Detalhes da Integra√ß√£o do SAM 2 no CVAT

### Passo a passo

A fun√ß√£o personalizada para o SAM 2 foi integrada ao CVAT utilizando Nuclio com suporte √† GPU. A fun√ß√£o recebe uma imagem e pontos de segmenta√ß√£o, executa o modelo SAM 2, gera a m√°scara e retorna a resposta ao CVAT. Essa integra√ß√£o melhora a acessibilidade √† segmenta√ß√£o avan√ßada de imagens.

### Mudan√ßas

| Arquivo/Fun√ß√£o                  | Descri√ß√£o                                                                                         |
|--------------------------------|---------------------------------------------------------------------------------------------------|
| `function-gpu.yaml`            | Define a configura√ß√£o da fun√ß√£o Nuclio: imagem base, runtime, handler, uso de GPU e vari√°veis ENV |
| `main.py`                      | Recebe imagem e pontos via HTTP e coordena a chamada ao `ModelHandler`                            |
| `model_handler.py`             | Cont√©m a l√≥gica de infer√™ncia, carregamento do modelo e suporte a Bounding Box                    |
| `deploy_gpu.sh`                | Script automatizado que percorre os diret√≥rios com `function-gpu.yaml` e executa o `nuctl deploy` |


### ‚öôÔ∏è Diferenciais desta implementa√ß√£o (SAM 2)

| Recurso                          | Descri√ß√£o                                                                 |
|----------------------------------|---------------------------------------------------------------------------|
| ‚úÖ ENV configur√°veis             | Permite trocar facilmente o modelo e config (`MODEL`, `MODEL_CFG`)       |
| ‚úÖ Bounding Box to Mask          | Suporte a caixas iniciais para gerar segmenta√ß√µes mais precisas          |
| ‚úÖ Compat√≠vel com CVAT + Nuclio  | Deploy simples via `deploy_gpu.sh` com `function-gpu.yaml` espec√≠fico    |
| üß† Baseada em SAM1               | Estrutura de fun√ß√£o herdada do `serverless/pytorch/facebookresearch/sam` |

---

### ‚ú® Comparativo com o SAM 1

| Item                         | SAM 1                                      | SAM 2 (custom adaptado)                      |
|------------------------------|---------------------------------------------|----------------------------------------------|
| Modelo base                  | SAM (v1)                                    | Segment Anything 2 (v2)                      |
| Bounding Box suporte         | ‚ùå Somente pontos                           | ‚úÖ Bounding Box + pontos                     |
| Vari√°veis de ambiente        | ‚ùå Fixas                                    | ‚úÖ `MODEL` e `MODEL_CFG`                     |
| Arquitetura Nuclio           | ‚úÖ Pronta                                   | ‚úÖ Adaptada a partir do SAM1                 |
| Imagem base CUDA             | `cuda11`                                    | `cuda12.4`, compat√≠vel com PyTorch 2.4       |

---

### ü§ù Agradecimentos

A adapta√ß√£o do SAM2 foi baseada em contribui√ß√µes da comunidade, especialmente nos pull requests da [issue #8243](https://github.com/opencv/cvat/pull/8243), liderada por @jeanchristopheruel, que tornou poss√≠vel integrar o Segment Anything 2 ao ecossistema CVAT Open Source.

### Diagrama de Sequ√™ncia

```mermaid
sequenceDiagram
    participant User
    participant HTTPTrigger
    participant MainHandler
    participant ModelHandler

    User->>HTTPTrigger: Send image and points
    HTTPTrigger->>MainHandler: Forward request
    MainHandler->>MainHandler: Initialize context
    MainHandler->>ModelHandler: Process image with points
    ModelHandler->>ModelHandler: Generate mask
    ModelHandler-->>MainHandler: Return mask
    MainHandler-->>HTTPTrigger: Send response with mask
    HTTPTrigger-->>User: Display result
```

---
---

## üßë‚Äçüíª Usando a anota√ß√£o autom√°tica na interface

1. Criar uma `Task`
2. Fazer upload de imagens
3. Criar um label (ex: `person`)
4. Acessar o Job
5. Clicar em `Actions ‚Üí Automatic Annotation`
6. Escolher o modelo
7. Mapear os labels e clicar em **Annotate**
8. Clicar em **Save**

---

## üìÑ Exportando anota√ß√µes

- `Actions ‚Üí Export annotations`
- Formatos suportados: COCO, YOLO, Pascal VOC, XML, etc.

---

## üìä Comparativo de Modelos

| Modelo  | Tipo       | Suporte     | Framework       | Recurso | Labels | Tipos de tarefa |
|---------|------------|-------------|------------------|---------|--------|-----------------|
| YOLOv3  | Detec√ß√£o   | Oficial     | OpenVINO         | CPU     | person, car... | Caixa delimitadora |
| DEXTR   | Segmenta√ß√£o| Oficial     | OpenVINO         | CPU     | custom          | Segmenta√ß√£o interativa |
| SAM 1   | Segmenta√ß√£o| Oficial     | PyTorch + CUDA    | GPU     | custom          | Segmenta√ß√£o assistida |
| SAM 2   | Segmenta√ß√£o| Custom      | PyTorch 2.4 + CUDA 12.4 | GPU | custom          | Segmenta√ß√£o assistida |

---

## üß™ Como foi feita a personaliza√ß√£o do SAM 2 no CVAT ?

---

### üìÅ Estrutura da fun√ß√£o customizada
```
deploy_gpu.sh                # Script que faz o deploy da fun√ß√£o via nuctl
sam2/
  ‚îî‚îÄ‚îÄ nuclio/
      ‚îú‚îÄ‚îÄ function-gpu.yaml  # Configura√ß√£o da fun√ß√£o Nuclio (GPU, ENV, modelo)
      ‚îú‚îÄ‚îÄ main.py            # Fun√ß√£o HTTP que trata a requisi√ß√£o do CVAT
      ‚îú‚îÄ‚îÄ model_handler.py   # Classe que roda a infer√™ncia do SAM2
```

---

### üîß `function-gpu.yaml`

- Define `baseImage: pytorch/pytorch:2.4.0-cuda12.4-cudnn9-devel`, conforme recomendado pela Meta para suporte ao SAM2
- Adiciona instru√ß√µes `directives` para instalar pacotes via `apt`, baixar o modelo SAM2 e instalar bibliotecas com `pip`
- Usa `resources.limits.nvidia.com/gpu: 1` para garantir que a fun√ß√£o utilize a GPU
- Usa vari√°veis de ambiente para parametrizar o modelo carregado:

```yaml
- kind: ENV
  value: MODEL="sam2_hiera_large.pt"
- kind: ENV
  value: MODEL_CFG="sam2_hiera_l.yaml"
```

Isso permite alternar entre diferentes variantes do SAM2 (tiny, small, base_plus, large) sem editar o c√≥digo.

---

### üß† `main.py`

- Implementa o `handler()` que:
  - Recebe a imagem base64 + pontos positivos e negativos
  - Converte a imagem para RGB
  - (Opcionalmente) processa `obj_bbox` se fornecido
  - Chama `ModelHandler.handle()` e retorna a m√°scara gerada como resposta JSON
- Inclui tratamento de erro com `try/except`, garantindo respostas HTTP 500 bem formatadas em caso de falha

---

### üß† `model_handler.py`

- Usa `torch.cuda.is_available()` para detectar e utilizar GPU
- Carrega dinamicamente o modelo e a configura√ß√£o definidos nas vari√°veis de ambiente
- Implementa:
  ```python
  def handle(image, pos_points, neg_points, obj_bbox=None)
  ```
  que realiza a infer√™ncia usando:
  ```python
  self.predictor.predict(...)
  ```
- Ordena as m√°scaras por `score`, retornando a melhor

- Se `obj_bbox` for fornecida, ela √© utilizada como pista para refinar a segmenta√ß√£o, permitindo a funcionalidade de **Bounding Box to Mask**

---

### üí° Destaques t√©cnicos da adapta√ß√£o

| Recurso                           | Implementado? | Detalhes                                                                 |
|----------------------------------|---------------|--------------------------------------------------------------------------|
| Suporte √† GPU (CUDA 12.4)        | ‚úÖ            | Imagem `pytorch:2.4.0-cuda12.4-cudnn9-devel`                             |
| Deploy autom√°tico via script     | ‚úÖ            | Com `deploy_gpu.sh` e `nuctl`                                            |
| ENV para modelo/config           | ‚úÖ            | Com `MODEL` e `MODEL_CFG`                                               |
| Suporte a Bounding Box to Mask   | ‚úÖ            | Parametrizado via `obj_bbox` em `main.py` e `model_handler.py`          |
| Base SAM1 reaproveitada          | ‚úÖ            | Estrutura da fun√ß√£o e l√≥gica mantidas e adaptadas                       |
| Escal√°vel e reutiliz√°vel         | ‚úÖ            | Pronto para automa√ß√µes futuras                                          |

---

## üìö Refer√™ncias

- [CVAT Docs](https://docs.cvat.ai/)
- [Nuclio Docs](https://nuclio.io/docs/latest/)
- [Segment Anything v1](https://github.com/facebookresearch/segment-anything)
- [Segment Anything v2](https://github.com/facebookresearch/segment-anything-2)

---

## ‚úÖ **Checklist Geral do Projeto**

### üîß Instala√ß√£o e Configura√ß√£o Base
- [x] Clonagem do reposit√≥rio oficial do [CVAT](https://github.com/opencv/cvat)
- [x] Uso do `docker-compose.yml` e `docker-compose.serverless.yml` para subir o CVAT com suporte a modelos serverless
- [x] Configura√ß√£o do Traefik para acesso via rede local (IP da m√°quina host)
- [x] Cria√ß√£o de superusu√°rio Django via container `cvat_server`
- [x] Instala√ß√£o do CLI `nuctl` para deploy de fun√ß√µes Nuclio
- [x] Instala√ß√£o dos drivers NVIDIA, CUDA Toolkit e NVIDIA Container Toolkit (essencial para SAM 1 e SAM 2)

---

### üß† Deploy dos Modelos Padr√£o
- [x] Deploy do **YOLOv3** com `deploy_cpu.sh`
- [x] Deploy do **DEXTR** com `deploy_cpu.sh`
- [x] Deploy do **SAM 1** com `deploy_gpu.sh` oficial

---

### üöÄ Integra√ß√£o e Deploy do SAM 2 (Custom Adaptado)
- [x] An√°lise de dois reposit√≥rios diferentes de SAM2
- [x] Escolha e uso do reposit√≥rio **com suporte a Bounding Box to Mask** e uso de `ENV`
- [x] Inclus√£o dos arquivos:
  - `function-gpu.yaml`
  - `main.py`
  - `model_handler.py`
  - `deploy_gpu.sh`
- [x] Configura√ß√£o de vari√°veis `ENV` no `function-gpu.yaml` (`MODEL`, `MODEL_CFG`)
- [x] Suporte a CUDA 12.4 via imagem base `pytorch/pytorch:2.4.0-cuda12.4-cudnn9-devel`
- [x] Adi√ß√£o de suporte a **Bounding Box to Mask**
- [x] Testes de deploy via `nuctl` e rein√≠cio do CVAT para reconhecimento autom√°tico da fun√ß√£o

---

### üìÇ Volume Compartilhado (Shared Storage)
- [x] Cria√ß√£o do volume `cvat_share` com bind para `/mnt/share`
- [x] Cria√ß√£o do arquivo `docker-compose.custom.override.yml`
- [x] Montagem do volume nos containers:
  - `cvat_server`
  - `cvat_worker_import`
  - `cvat_worker_export`
  - `cvat_worker_annotation`
  - `cvat_worker_chunks`
- [x] Teste de leitura/escrita com `echo` e `cat` dentro do container
- [x] Permiss√µes aplicadas: `chmod 777 /mnt/share`

---
